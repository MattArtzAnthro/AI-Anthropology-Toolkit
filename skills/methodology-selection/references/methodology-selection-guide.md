# Methodology Selection Guide

Decision workflow, criteria, failure modes, and checklist for selecting and
justifying research methods in anthropological and qualitative research.

## Decision Criteria

A defensible method selection optimizes across these criteria, in roughly this
order (earlier criteria dominate later ones):

### 1. Epistemic Stance Constraints (Non-Negotiable)

Define what counts as evidence; what the researcher is allowed to claim; how
reflexivity, positionality, and power are treated; whether explanation is
causal, interpretive, critical, or interventionist. Method choice is secondary
to these commitments — questions of method follow from questions of paradigm.

### 2. Research Question Features (Evidence Requirements)

Translate the question into required evidence types:

- **Embodied practices** — requires observation
- **Meaning-making** — requires interpretive elicitation plus context
- **Distributions** — requires standardized measurement
- **Discourse-in-use** — requires recordings and transcription
- **Historical sequence** — requires archives
- **Network/process across sites** — requires multi-sited or trace strategies
- **Materiality** — requires object-oriented or sensory methods

### 3. Scale and Boundedness

Small-N intensive sensemaking differs from multi-population pattern estimation.
Methods can be coherent across paradigms, but the design logic must make scale
explicit (depth, breadth, or both).

### 4. Temporal Scope

Cross-sectional present ethnography differs from longitudinal change, event
history, or archival time. Archival-ethnographic designs require explicit
integration of temporalities (then and now).

### 5. Access and Field Conditions

Where observation is impossible or risky, trace and documentary methods become
more central. Where recruitment is constrained, sampling logic must shift
(purposive, snowball, theoretical).

### 6. Ethics and Data Governance

Risk, identifiability, consent feasibility, and future harms (including harms
from data circulation) are design determinants, not afterthoughts. Ethnographic
materials are co-produced, relational, and context-embedded; consent is often
ongoing and cannot always be fully specified in advance.

### 7. Feasibility (Resources, Skills, Time)

Methods that cannot be implemented with rigor are not "best" methods. Short
timelines may favor telescoped, team-based, triangulated approaches (rapid
assessment) when appropriate.

---

## Decision Workflow

Follow this sequence to move from research question and stance to a defensible
method system:

### Step 1: Define the Claim Envelope

Based on the epistemic stance, state what kinds of claims are admissible and
what kinds are not:

- An interpretivist project makes claims about **meaning**, not prevalence
- A critical project makes claims about **power**, not neutral description
- A phenomenological project makes claims about **lived experience**, not
  causal mechanisms
- A cognitive anthropology project makes claims about **shared knowledge
  structures**, not individual psychology
- An STS project makes claims about **associations among heterogeneous
  actors**, not isolated beliefs

### Step 2: Decompose the Question into Evidence Needs

Translate each research question into the specific evidence types required to
answer it. Use the evidence categories from the decision criteria above.

### Step 3: Generate Candidate Method Modules

From the 14 method modules (see method-modules.md), identify which could
produce the required evidence types. At this stage, generate broadly — the
filtering happens in the next steps.

### Step 4: Check Epistemic Coherence

Using the compatibility matrix (see method-stance-compatibility.md), rate each
candidate method against the user's stance:

- **S (Standard)** — common and reviewer-legible within the stance family;
  expected evidentiary moves
- **C (Coherent)** — epistemically compatible but not always expected; requires
  explicit framing to avoid "category error"
- **I (Innovative/defensible)** — less common but justifiable with careful
  design, validation, and reflexive argumentation
- **T (High-tension)** — not forbidden, but likely to be evaluated as
  incoherent unless the stance is explicitly adapted (often by reframing
  claims or adding participatory governance)

Flag any T-rated methods and explain what reframing would be needed.

### Step 5: Check Field Constraints

Filter candidates by:
- Access (can you actually do this at your site?)
- Risk (does this method create unacceptable risks?)
- Consent feasibility (can you obtain meaningful consent for this method?)
- Platform terms (for digital methods: do ToS permit this?)
- Legality (especially cross-border data, surveillance contexts)
- Resource availability (time, funding, skills, personnel)

### Step 6: Compose the Multi-Method System

Assign each surviving method a role:
- **Primary evidence generation** — produces the core evidence for the
  research question
- **Complementary perspective** — provides a different angle on the same
  phenomenon
- **Contextualization** — supplies background, history, or institutional
  framing
- **Validation** — tests or triangulates claims from other methods

Ensure the system has internal logic — methods should relate to each other,
not just coexist.

### Step 7: Specify the Integration Plan

State:
- When and where evidence streams are joined
- What analytic strategy governs integration
- What meta-inferences result
- What convergence or divergence between streams would mean

Do not use "triangulation" without specifying the type (data, method, theory)
and what convergence or divergence means for inference.

---

## Mapping to Upstream and Downstream Skills

The methodology-selection skill sits in a specific position in the research
design workflow:

**Upstream inputs (from research-question skill):**
- Phenomenon specification and unit of analysis
- Evidence types required
- Claim scope (what would count as an answer)

**This skill produces:**
- Stance declaration (and family)
- Method-system composition (modules + roles)
- Integration plan (when/how evidence is joined)
- Implementation spec (sampling, access plan, protocols, analysis plan)
- Ethics and data governance plan

**Downstream consumers (research-plan, grant-proposal skills):**
- Methods section that answers: what you will do, how, and why these steps
  yield needed information; plus feasibility detail
- Data management and sharing plan where required
- Program-specific rhetoric for funders

---

## Proposal-Ready Phrasing Patterns

These fill-in templates can be adapted with project-specific nouns and
constraints:

**Method justification:**
"To answer [RQ], I require evidence of [evidence types]. I therefore combine
[method A] to produce [evidence X] with [method B] to produce [evidence Y];
together these support claims about [claim envelope], while explicitly not
claiming [out-of-scope claim]."

**Integration statement:**
"Integration occurs at [stage], when [data streams] are joined through
[analytic strategy] to generate [meta-inferences]."

**Ethics and governance statement:**
"Ethical governance is designed into the methods: informed consent is treated
as ongoing; materials are stored under [custodianship/embargo rules]; and
publication choices prioritize minimizing re-identification and future harms."

---

## Common Failure Modes and Remediations

### Failure: Methods as a Grocery List

**Symptom:** "I will do observation, interviews, and surveys" without stating
what each contributes and how results will be integrated.

**Remediation:** Require a one-sentence role statement per method module:
"This method produces X evidence to support Y type of claim; it is limited
by Z; it is integrated with method Q at stage T."

### Failure: Generic Justification

**Symptom:** "Participant observation is a hallmark of anthropology."

**Remediation:** Enforce stance-and-question anchoring: "Participant
observation is necessary here because the phenomenon is embodied/context-
dependent and because the stance requires interpreting practices in situ."

### Failure: Stance-Method Mismatch Hidden by Vague Language

**Symptom:** Interpretive project using surveys but claiming measurement-like
objectivity; computational project using models without validation; critical
project claiming "neutrality" while doing critique.

**Remediation:** Add a claim envelope step that forces explicit statements
about what counts as evidence and what validation will look like. Automated
text analysis, for example, is defensible when validation and close reading
are built in, not when the model is treated as self-authenticating.

### Failure: Integration Left Implicit

**Symptom:** "Triangulation" used as a magic word.

**Remediation:** Specify the type of triangulation (data, method, theory) and
what convergence or divergence will mean for inference.

### Failure: Sample Size Justified by Round Numbers or Unexamined "Saturation"

**Remediation:** Use defensible logics such as information power (aim,
specificity, theory, quality of dialogue, analysis strategy) or empirically
grounded saturation expectations. Multi-site projects often require larger
samples for cross-site metathemes than homogeneous single-site studies.

### Failure: Ethics Treated as Appendix

**Remediation:** Require an explicit data governance plan: consent as ongoing,
identifiability analysis, storage and embargo choices, and rules for future
sharing. Ethnographic materials are co-produced, and governance must address
custodianship, embargo options, and constraints on prior consent.

---

## Actionable Checklist

Use this checklist as an evaluator. If any box is unchecked, the methodology
is usually not yet reviewer-ready.

- [ ] Epistemic stance (or stance family) is named and the claim envelope is
      stated: what kinds of claims will and will not be made
- [ ] Each research question is translated into specific evidence needs
      (practices, meanings, discourse, distributions, histories, traces,
      materiality)
- [ ] For every method module, a one-sentence role statement is written:
      evidence produced, claim supported, limitation
- [ ] Each method is justified in relation to (a) the stance and (b) the
      specific question, not as a generic "anthropology standard"
- [ ] Sampling logic (purposive/snowball/theoretical or probability) is
      specified and anticipated sample sizes are justified using information
      power or defensible saturation reasoning
- [ ] Implementation details are sufficient for evaluation: sites/settings,
      recruitment, instruments, recording, transcription, fieldnote protocols
- [ ] An explicit integration plan exists for multi-method projects: when and
      how evidence streams are combined, and what meta-inferences result
- [ ] If using computational methods: a validation plan is specified (close
      reading, triangulation, error analysis); model outputs are not treated
      as self-validating
- [ ] If doing digital research: internet-specific ethics are addressed
      (public/private ambiguity, searchability, platform governance, identifier
      protection)
- [ ] An ethics and data governance plan is included: ongoing consent logic,
      risk analysis, storage security, embargo rules, and publication choices
      that reduce future harms
- [ ] Limitations and what the design cannot know are stated in
      stance-appropriate terms
- [ ] A timeline and feasibility rationale show the work can be completed with
      available time and resources
- [ ] If required by funder: a data management and sharing plan is included
      that is consistent with ethnographic ethics and confidentiality
      constraints
